{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code used to obtain data from Google Books\n",
    "\n",
    "Attributes obtained: \n",
    " - ISBN13, ISBN10, Google Books ID ( Primary Keys of the Book )\n",
    " - Name, Subtitle, Description, Page Count of the book \n",
    " - Author(s), Publisher(s), Originally Published Date of the book\n",
    " - Language, Genre(s), Maturity Rating of the book\n",
    " - Availability of the book ( as an eBook, ePub and PDF )\n",
    " - Thumbnail Links to the Cover Images of the book\n",
    " - List of books belonging to the same franchise/series if any\n",
    " - List of books published by the same publisher(s) if any \n",
    " - List of books written by the same first author if any\n",
    " - List of editions of the same book, and details on their ISBN IDs, formats, date of publishing, publisher and page count if any\n",
    "\n",
    "\n",
    "Also, this Notebook also has a piece of code used to obtain links from OpenLibrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Books Data Collection - Attributes Part 1\n",
    "\n",
    "The Google Books API was used to obtain data here, and this data was read using urllib and json, and parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Pranav\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "def api_details_provider(isbn):\n",
    "    base_api_link = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n",
    "    user_input = str(isbn)\n",
    "    with urllib.request.urlopen(base_api_link + user_input) as f:\n",
    "        text = f.read()\n",
    "\n",
    "    decoded_text = text.decode(\"utf-8\")\n",
    "    obj = json.loads(decoded_text) # deserializes decoded_text to a Python object\n",
    "    \n",
    "    try:\n",
    "        detailsdict = {}\n",
    "        detailsdict = {'status':1}\n",
    "        volume_info = obj[\"items\"][0] \n",
    "\n",
    "        try:\n",
    "            detailsdict.update({'isbn_13':volume_info[\"volumeInfo\"][\"industryIdentifiers\"][0][\"identifier\"]})\n",
    "        except:\n",
    "            detailsdict.update({'isbn_13':\"\"})\n",
    "                        \n",
    "        try:\n",
    "            detailsdict.update({'isbn_10':volume_info[\"volumeInfo\"][\"industryIdentifiers\"][1][\"identifier\"]})\n",
    "        except:\n",
    "            detailsdict.update({'isbn_10':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'book_title':volume_info[\"volumeInfo\"][\"title\"]})\n",
    "        except:\n",
    "            detailsdict.update({'book_title':\"\"})\n",
    "        \n",
    "        try:\n",
    "            detailsdict.update({'subtitle':volume_info[\"volumeInfo\"][\"subtitle\"]})\n",
    "        except:\n",
    "            detailsdict.update({'subtitle':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'authors':volume_info[\"volumeInfo\"][\"authors\"]})\n",
    "        except:\n",
    "            detailsdict.update({'authors':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'publisher':volume_info[\"volumeInfo\"][\"publisher\"]})\n",
    "        except:\n",
    "            detailsdict.update({'publisher':\"\"})\n",
    "            \n",
    "           \n",
    "        try:\n",
    "            detailsdict.update({'published_date':volume_info[\"volumeInfo\"][\"publishedDate\"]})\n",
    "        except:\n",
    "            detailsdict.update({'published_date':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'page_count':volume_info[\"volumeInfo\"][\"pageCount\"]})\n",
    "        except:\n",
    "            detailsdict.update({'page_count':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'categories':volume_info[\"volumeInfo\"][\"categories\"]})\n",
    "        except:\n",
    "            detailsdict.update({'categories':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'small_thumbnail_link':volume_info[\"volumeInfo\"][\"imageLinks\"][\"smallThumbnail\"]})\n",
    "        except:\n",
    "            detailsdict.update({'small_thumbnail_link':\"\"})\n",
    "        \n",
    "        try:\n",
    "            detailsdict.update({'large_thumbnail_link':volume_info[\"volumeInfo\"][\"imageLinks\"][\"thumbnail\"]})\n",
    "        except:\n",
    "            detailsdict.update({'large_thumbnail_link':\"\"})\n",
    "        \n",
    "        try:\n",
    "            detailsdict.update({'average_rating':volume_info[\"volumeInfo\"][\"averageRating\"]})\n",
    "        except:\n",
    "            detailsdict.update({'average_rating':-1})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'ratings_count':volume_info[\"volumeInfo\"][\"ratingsCount\"]})\n",
    "        except:\n",
    "            detailsdict.update({'ratings_count':-1})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'maturity_rating':volume_info[\"volumeInfo\"][\"maturityRating\"]})\n",
    "        except:\n",
    "            detailsdict.update({'maturity_rating':\"\"})\n",
    "        \n",
    "        try:\n",
    "            detailsdict.update({'description':volume_info[\"volumeInfo\"][\"description\"]})\n",
    "        except:\n",
    "            detailsdict.update({'description':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'language':volume_info[\"volumeInfo\"][\"language\"]})\n",
    "        except:\n",
    "            detailsdict.update({'language':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'preview_link':volume_info[\"volumeInfo\"][\"previewLink\"]})\n",
    "        except:\n",
    "            detailsdict.update({'preview_link':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'info_link':volume_info[\"volumeInfo\"][\"infoLink\"]})\n",
    "        except:\n",
    "            detailsdict.update({'info_link':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'canonical_volume_link':volume_info[\"volumeInfo\"][\"canonicalVolumeLink\"]})\n",
    "        except:\n",
    "            detailsdict.update({'canonical_volume_link':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'self_link':volume_info[\"selfLink\"]})\n",
    "        except:\n",
    "            detailsdict.update({'self_link':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'etag':volume_info[\"etag\"]})\n",
    "        except:\n",
    "            detailsdict.update({'etag':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'availability_as_ebook':volume_info[\"saleInfo\"][\"isEbook\"]})\n",
    "        except:\n",
    "            detailsdict.update({'availability_as_ebook':\"\"})\n",
    "            \n",
    "        try:\n",
    "            detailsdict.update({'cost':volume_info[\"saleInfo\"][\"retailPrice\"][\"amount\"]})\n",
    "        except:\n",
    "            detailsdict.update({'cost':\"\"})\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        detailsdict.update({'status':0})\n",
    "    \n",
    "    return detailsdict\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"isbn_input.csv\")\n",
    "print(df.iloc[0]['isbn13'])\n",
    "df = df.astype(str)\n",
    "for i in range(2001,4001):\n",
    "    time.sleep(0.75)\n",
    "    if True:\n",
    "        df.to_csv('new_output.csv')\n",
    "    x = df.iloc[i]['isbn13']\n",
    "    d = api_details_provider(x)\n",
    "    if d['status']==0:\n",
    "        print(i,\"     \",x,\" not found.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(i,\"     \",x, \"found. Update in progress...\",end='')\n",
    "        df.at[i,'isbn_13'] = d['isbn_13']\n",
    "        df.at[i,'isbn_10'] = d['isbn_10']\n",
    "        df.at[i,'book_title'] = d['book_title']\n",
    "        df.at[i,'subtitle'] = d['subtitle']\n",
    "        df.at[i,'authors'] = d['authors']\n",
    "        df.at[i,'publisher'] = d['publisher']\n",
    "        df.at[i,'published_date'] = d['published_date']\n",
    "        df.at[i,'page_count'] = d['page_count']\n",
    "        df.at[i,'categories'] = d['categories']\n",
    "        df.at[i,'small_thumbnail_link'] = d['small_thumbnail_link']\n",
    "        df.at[i,'large_thumbnail_link'] = d['large_thumbnail_link']\n",
    "        df.at[i,'average_rating'] = int(d['average_rating'])\n",
    "        df.at[i,'ratings_count'] = d['ratings_count']\n",
    "        df.at[i,'maturity_rating'] = d['maturity_rating']\n",
    "        df.at[i,'description'] = d['description']\n",
    "        df.at[i,'language'] = d['language']\n",
    "        df.at[i,'preview_link'] = d['preview_link']\n",
    "        df.at[i,'info_link'] = d['info_link']\n",
    "        df.at[i,'canonical_volume_link'] = d['canonical_volume_link']\n",
    "        df.at[i,'self_link'] = d['self_link']\n",
    "        df.at[i,'etag'] = d['etag']\n",
    "        df.at[i,'availability_as_ebook'] = d['availability_as_ebook']\n",
    "        df.at[i,'cost'] = d['cost']\n",
    "\n",
    "        \n",
    "\n",
    "        print(\"Finished.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Books Data Collection - Attributes Part 2\n",
    "\n",
    "The Google Books new website was used to search for each ISBN and scrape details using Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import date \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "#book_editions,book_series,more_by_author,similar_books,publisher_collection\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "df = pd.read_csv(\"books_v5.csv\")\n",
    "df = df.astype({'book_editions':str,'book_series':str,'more_by_author':str,'similar_books':str,'publisher_collection':str})\n",
    "\n",
    "\n",
    "for j in range(2804,3251):\n",
    "    \n",
    "    title = df.iloc[j]['book_title']\n",
    "    driver.get(r'https://www.google.co.in/books/edition/The_Four_Loves/69_-CwAAQBAJ?hl=en')\n",
    "    \n",
    "    search_box = driver.find_element_by_xpath(\"//form[@action='/search']//input[1]\")\n",
    "    search_box.send_keys(title)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    print(\"###############################\")\n",
    "    print(\"### \",title,\" #####\")\n",
    "    print(\"###############################\")\n",
    "\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        other_editions = driver.find_element_by_xpath(\"//span[text()='More editions']\") \n",
    "        other_editions.click()\n",
    "\n",
    "        \n",
    "        \n",
    "        #//div[@id='bep-editions']/div[1]/div[2]/div[1]/div[1]/div[1]/a[1]/div[1]\n",
    "        lis = []\n",
    "        for i in range(1,15):\n",
    "            sublis = []\n",
    "            try:\n",
    "                \n",
    "                edition_title = driver.find_element_by_xpath(\"//div[@id='bep-editions']/div[1]/div[{}]/div[1]/div[1]/div[1]/a[1]/div[1]\".format(i)).text\n",
    "                print(\"-------------EDITION {}-----------\".format(i))\n",
    "                try:\n",
    "                    edition_ISBN = driver.find_element_by_xpath(\"(//div[text()='ISBN:  '])[{}]\".format(i)).text.split(':  ')[1]\n",
    "                    sublis.append(edition_ISBN)\n",
    "                except:\n",
    "                    sublis.append(\"\")\n",
    "\n",
    "                try:\n",
    "                    edition_format = driver.find_element_by_xpath(\"(//div[text()='Format:  '])[{}]\".format(i)).text.split(':  ')[1]\n",
    "                    sublis.append(edition_format)\n",
    "                except:\n",
    "                    sublis.append(\"\")\n",
    "\n",
    "                try:\n",
    "                    edition_publisher = driver.find_element_by_xpath(\"(//div[text()='Publisher:  '])[{}]\".format(i)).text.split(':  ')[1]\n",
    "                    sublis.append(edition_publisher)\n",
    "                except:\n",
    "                    sublis.append(\"\")\n",
    "\n",
    "                try:\n",
    "                    edition_published = driver.find_element_by_xpath(\"(//div[text()='Published:  '])[{}]\".format(i)).text.split(':  ')[1]\n",
    "                    sublis.append(edition_published)\n",
    "                except:\n",
    "                    sublis.append(\"\")\n",
    "\n",
    "                try:\n",
    "                    edition_length = driver.find_element_by_xpath(\"(//div[text()='Length:  '])[{}]\".format(i)).text.split(':  ')[1]\n",
    "                    sublis.append(edition_length)\n",
    "                except:\n",
    "                    sublis.append(\"\")\n",
    "\n",
    "                lis.append(sublis)\n",
    "                \n",
    "            except:\n",
    "                print(\"-------NUMBER OF EDITIONS ENDS HERE-----\")\n",
    "                break\n",
    "\n",
    "        print(lis)\n",
    "        df.at[j,'book_editions'] = lis\n",
    "        \n",
    "    except:\n",
    "        print(\"------EDITIONS PAGE DOES NOT EXIST-------\")\n",
    "\n",
    "         \n",
    "    try:\n",
    "        series = driver.find_element_by_xpath(\"//span[text()='Series']\")\n",
    "        series.click()\n",
    "        time.sleep(2)\n",
    "        slis = []\n",
    "        for i in range(1,10):\n",
    "            try:\n",
    "                series_name = driver.find_element_by_xpath(\"//div[@id='bep-tab-series']/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[{}]/div[1]/div[1]/a[1]/div[1]\".format(i)).text\n",
    "                print(\"-------------SERIES - LISTING {}-----------\".format(i))\n",
    "                slis.append(series_name)\n",
    "            except:\n",
    "                print(\"-------NUMBER OF SERIES LISTINGS END HERE-----\")\n",
    "                break\n",
    "        print(slis)\n",
    "        df.at[j,'book_series'] = slis\n",
    "    except:\n",
    "        print(\"------SERIES PAGE DOES NOT EXIST-------\")\n",
    "    \n",
    "\n",
    "    try:\n",
    "        more_by_author = driver.find_element_by_xpath(\"//span[text()='More by author']\")\n",
    "        more_by_author.click()\n",
    "        time.sleep(2)\n",
    "        mlis = []\n",
    "        for i in range(1,10):\n",
    "            try:\n",
    "                more_name = driver.find_element_by_xpath(\"//div[@id='bep-tab-content']/g-flippy-carousel[1]/div[1]/div[1]/ol[1]/li[5]/span[1]/div[1]/div[1]/div[1]/div[1]/div[3]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[{}]/div[1]/div[1]/a[1]/div[1]\".format(i)).text\n",
    "                print(\"-------------MORE BY THE AUTHOR - LISTING {}-----------\".format(i))\n",
    "                mlis.append(more_name)\n",
    "            except:\n",
    "                print(\"-------NUMBER OF MORE BY THE AUTHOR LISTINGS END HERE-----\")\n",
    "                break\n",
    "        print(mlis)\n",
    "        df.at[j,'more_by_author'] = mlis\n",
    "    except:\n",
    "         print(\"------MORE BY THE AUTHOR PAGE DOES NOT EXIST-------\")\n",
    "\n",
    "    \n",
    "   \n",
    "    try:\n",
    "        similar_books = driver.find_element_by_xpath(\"//span[text()='Similar books']\")\n",
    "        similar_books.click()\n",
    "        time.sleep(2)\n",
    "        simlis = []\n",
    "        for i in range(1,15):\n",
    "            try:\n",
    "                sim_name = driver.find_element_by_xpath(\"//div[@id='bep-tab-sideways']/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[{}]/div[1]/div[1]/a[1]/div[1]\".format(i)).text\n",
    "                print(\"-------------SIMILAR BOOKS - LISTING {}-----------\".format(i))\n",
    "                simlis.append(sim_name)\n",
    "            except:\n",
    "                print(\"-------NUMBER OF SIMILAR BOOKS LISTINGS END HERE-----\")\n",
    "                break\n",
    "        print(simlis)\n",
    "        df.at[j,'similar_books'] = simlis\n",
    "    except:\n",
    "        print(\"------SIMILAR BOOKS PAGE DOES NOT EXIST-------\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        publisher_collection = driver.find_element_by_xpath(\"//span[text()='Publisher collection']\")\n",
    "        publisher_collection.click()\n",
    "        time.sleep(2)\n",
    "        publis = []\n",
    "        for i in range(1,15):\n",
    "            try:\n",
    "                pub_name = driver.find_element_by_xpath(\"//div[@id='bep-tab-content']/g-flippy-carousel[1]/div[1]/div[1]/ol[1]/li[5]/span[1]/div[1]/div[1]/div[1]/div[1]/div[3]/div[1]/div[2]/div[1]/div[4]/div[1]/div[1]/div[{}]/div[1]/div[1]/a[1]/div[1]\".format(i)).text\n",
    "                print(\"-------------PUBLISHER COLLECTION - LISTING {}-----------\".format(i))\n",
    "                publis.append(pub_name)\n",
    "            except:\n",
    "                print(\"-------PUBLISHER COLLECTION LISTINGS END HERE-----\")\n",
    "                break\n",
    "        print(publis)\n",
    "        df.at[j,'publisher_collection'] = simlis\n",
    "    except:\n",
    "        print(\"------PUBLISHER COLLECTION PAGE DOES NOT EXIST-------\")\n",
    "    \n",
    "    df.to_csv(\"books_v5.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenLibrary Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import date \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"books_v5.csv\")\n",
    "df = df.astype({'univ_link':str})\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "for i in range(0,3251):\n",
    "    title = df.iloc[i]['book_title']\n",
    "    driver.get(r'https://openlibrary.org/advancedsearch')\n",
    "\n",
    "    search_title = driver.find_element_by_xpath(\"(//input[@name='title'])[1]\")\n",
    "    search_title.send_keys(title)\n",
    "\n",
    "    submit_button = driver.find_element_by_xpath(\"(//input[@type='submit'])[2]\")\n",
    "    submit_button.click()\n",
    "\n",
    "    try:\n",
    "        first_result = driver.find_element_by_xpath(\"(//a[@class='results'])[1]\")\n",
    "        first_result.click()\n",
    "        x = driver.current_url\n",
    "        print(i,\"  \",title,\"   \",x)\n",
    "        df.at[i,'univ_link']=x\n",
    "    except:\n",
    "        print(\"{} URL not available\".format(title))\n",
    "    df.to_csv(\"books_v5.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
